{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Traceback (most recent call last):\n",
       "  File \"c:\\Users\\acaua\\.vscode\\extensions\\ms-python.python-2024.20.0-win32-x64\\python_files\\python_server.py\", line 130, in exec_user_input\n",
       "    retval = callable_(user_input, user_globals)\n",
       "  File \"<string>\", line 1\n",
       "    %pip install numpy\n",
       "    ^\n",
       "SyntaxError: invalid syntax\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pip install numpy\n",
    "%pip install pandas\n",
    "%pip install scikit-learn\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory of 'src' to sys.path\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "\n",
    "# Importação de bibliotecas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from neural_network.utils import one_hot_encode, normalize_data, plot_confusion_matrix, plot_learning_curve\n",
    "from neural_network.losses import CategoricalCrossEntropyLoss\n",
    "from neural_network.layers.dense_layer import DenseLayer\n",
    "from neural_network.layers.dropout_layer import DropoutLayer\n",
    "from neural_network.optimizer import GradientDescent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar o arquivo CSV\n",
    "data = pd.read_csv('../data/multiclass/online_gaming_behavior.csv')\n",
    "\n",
    "# Exibir primeiras linhas do dataset\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionar colunas categóricas\n",
    "categorical_columns = ['Gender', 'Location', 'GameGenre', 'GameDifficulty', 'EngagementLevel']\n",
    "\n",
    "# Mapear cada categoria para um número\n",
    "for column in categorical_columns:\n",
    "    data[column] = data[column].astype('category').cat.codes\n",
    "\n",
    "# Obter o número de classes para cada coluna categórica\n",
    "num_classes = {column: data[column].nunique() for column in categorical_columns}\n",
    "\n",
    "# Aplicar One-Hot Encoding\n",
    "for column in categorical_columns:\n",
    "    one_hot_encoded = one_hot_encode(data[column].values, num_classes[column])\n",
    "\n",
    "    # Adicionar as colunas one-hot ao dataframe\n",
    "    for i in range(num_classes[column]):\n",
    "        data[f\"{column}_{i}\"] = one_hot_encoded[:, i]\n",
    "\n",
    "    # Remover a coluna categórica original\n",
    "    data = data.drop(column, axis=1)\n",
    "\n",
    "# Exibir o dataset transformado\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir X (entrada) e y (saída)\n",
    "X = data.drop(['PlayerID', 'EngagementLevel_0', 'EngagementLevel_1', 'EngagementLevel_2'], axis=1).values\n",
    "y = one_hot_encode(data[['EngagementLevel_0', 'EngagementLevel_1', 'EngagementLevel_2']].values.argmax(axis=1), 3)\n",
    "\n",
    "# Normalizar os dados de entrada\n",
    "X = normalize_data(X)\n",
    "\n",
    "# Dividir em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, layers, loss, optimizer):\n",
    "        self.layers = layers\n",
    "        self.loss = loss\n",
    "        self.optimizer = optimizer\n",
    "        \n",
    "    def forward(self, X):\n",
    "        output = X\n",
    "        for layer in self.layers:\n",
    "            output = layer.forward(output)\n",
    "        return output\n",
    "    \n",
    "    def backward(self, y_true, y_pred):\n",
    "        grad = self.loss.backward(y_true, y_pred)\n",
    "        for layer in reversed(self.layers):\n",
    "            grad = layer.backward(grad)\n",
    "    \n",
    "    def update(self):\n",
    "        for layer in self.layers:\n",
    "            params = layer.get_parameters()\n",
    "            if params:\n",
    "                grads = layer.get_gradients()\n",
    "                weights_updated, biases_updated = self.optimizer.update(\n",
    "                    params['weights'], params['biases'],\n",
    "                    grads['weights'], grads['biases']\n",
    "                )\n",
    "                layer.set_parameters({'weights': weights_updated, 'biases': biases_updated})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir a arquitetura da rede neural\n",
    "input_size = X_train.shape[1]\n",
    "output_size = y_train.shape[1]\n",
    "\n",
    "layers = [\n",
    "    DenseLayer(input_size=input_size, output_size=32, activation='relu'),\n",
    "    DropoutLayer(rate=0.2),\n",
    "    DenseLayer(input_size=32, output_size=24, activation='relu'),\n",
    "    DropoutLayer(rate=0.2),\n",
    "    DenseLayer(input_size=24, output_size=16, activation='relu'),\n",
    "    DropoutLayer(rate=0.2),\n",
    "    DenseLayer(input_size=16, output_size=8, activation='relu'),\n",
    "    DropoutLayer(rate=0.2),\n",
    "    DenseLayer(input_size=16, output_size=output_size, activation='softmax')\n",
    "]\n",
    "\n",
    "# Definir a função de perda e otimizador\n",
    "loss = CategoricalCrossEntropyLoss()\n",
    "optimizer = GradientDescent(learning_rate=0.01)\n",
    "\n",
    "# Criar o modelo\n",
    "model = NeuralNetwork(layers=layers, loss=loss, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinar a rede neural\n",
    "epochs = 800\n",
    "for epoch in range(epochs):\n",
    "    y_pred = model.forward(X_train)\n",
    "    loss_value = loss.calculate(y_train, y_pred)\n",
    "    model.backward(y_train, y_pred)\n",
    "    model.update()\n",
    "\n",
    "    # Exibir métricas a cada 50 épocas\n",
    "    if (epoch + 1) % 50 == 0:\n",
    "        predictions = y_pred.argmax(axis=1)\n",
    "        y_true = y_train.argmax(axis=1)\n",
    "        acc = accuracy_score(y_true, predictions)\n",
    "        print(f\"Epoch {epoch + 1}, Loss: {loss_value:.4f}, Accuracy: {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazer previsões no conjunto de teste\n",
    "y_pred_test = model.forward(X_test)\n",
    "predictions_test = y_pred_test.argmax(axis=1)\n",
    "y_true_test = y_test.argmax(axis=1)\n",
    "\n",
    "# Calcular métricas de desempenho\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true_test, predictions_test))\n",
    "\n",
    "# Acurácia\n",
    "accuracy = accuracy_score(y_true_test, predictions_test)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usar a função plot_confusion_matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "plot_confusion_matrix(y_test, predictions_test, labels=[\"Low\", \"Medium\", \"High\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usar a função plot_learning_curve\n",
    "plot_learning_curve(model, X_train, y_train, accuracy)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
